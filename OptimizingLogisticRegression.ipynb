{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4: Optimizing Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will continue practicing the fourth step of the machine learning life cycle and train logistic regression models that will be used to solve a classification problem.  You will build many variants, each one with a different value of the $C$ hyperparameter, which governs the amount of regularization used. Regularization is a process where we add a \"penalty\" to the original log loss function. This penalty is a function of the magnitudes of the weights learned in the Logistic Regression. The following shows the regularized log loss using what is called \"L2\" regularization.<br><br> \n",
    "\n",
    "<center>$Regularized \\ LogLoss = -\\frac{1}{N} \\sum\\limits_{i=1}^N (y_ilog(P_i)+(1-y_i)log(1-P_i))+\\frac{1}{C} \\sum\\limits_{j=1}^m w_j^2$</center><br><br>\n",
    "\n",
    "\n",
    "With L2 regularization, the penalty is the sum of the squares of the weights scaled by a constant $1/C$. When the hyperparameter $C$ is large, we reduce the weight of the penalty, which results in less regularization. You will build Logistic regressions with different values of $C$ and will check how this impacts the log loss.\n",
    "\n",
    "\n",
    "You will complete the following tasks:\n",
    "\n",
    "1. Build your DataFrame and define your ML problem:\n",
    "    * Load the \"cell2cell\" data set into a DataFrame\n",
    "    * Define the label - what are you predicting?\n",
    "    * Identify features\n",
    "3. Create labeled examples from the data set\n",
    "4. Split the data into training and test data sets\n",
    "5. Train logistic regression classifiers and evaluate their performances:\n",
    "    * Fit logistic regression models to the training data using different hyperparameter values per classifier\n",
    "    * Evaluate the accuracy of each model's predictions\n",
    "    * Plot and analyize the resulting log loss and accuracy scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Build Your DataFrame and Define Your ML Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load a Data Set and Save it as a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with the \"cell2celltrain\" data set. This version of the data set has been preprocessed and is ready for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not remove or edit the line below:\n",
    "filename = os.path.join(os.getcwd(), \"data\", \"cell2celltrain.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Load the data and save it to DataFrame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Label\n",
    "\n",
    "This is a binary classification problem in which we will predict customer churn. The label is the `Churn` column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify Features\n",
    "\n",
    "To implement a Logistic Regression model, we must use only the numeric columns. \n",
    "\n",
    "\n",
    "<b>Task</b>: Use the Pandas DataFrame <code>select_dtypes()</code> method to obtain all of names of columns that have a dtype of \"float64.\" Save the result to a list named `feature_list`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = df.select_dtypes(include=['float64']).columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Create Labeled Examples from the Data Set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is fully prepared for modeling. We can now create labeled examples from DataFrame `df`.\n",
    "\n",
    "<b>Task</b>: Obtain the feature columns from DataFrame `df` and assign to `X`. Obtain the label column from DataFrame `df` and assign to `y`.\n",
    "\n",
    "You should have 51047 labeled examples. Each example contains 35 features and one label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MonthlyRevenue</th>\n",
       "      <th>MonthlyMinutes</th>\n",
       "      <th>TotalRecurringCharge</th>\n",
       "      <th>DirectorAssistedCalls</th>\n",
       "      <th>OverageMinutes</th>\n",
       "      <th>RoamingCalls</th>\n",
       "      <th>PercChangeMinutes</th>\n",
       "      <th>PercChangeRevenues</th>\n",
       "      <th>DroppedCalls</th>\n",
       "      <th>BlockedCalls</th>\n",
       "      <th>...</th>\n",
       "      <th>HandsetModels</th>\n",
       "      <th>CurrentEquipmentDays</th>\n",
       "      <th>AgeHH1</th>\n",
       "      <th>AgeHH2</th>\n",
       "      <th>RetentionCalls</th>\n",
       "      <th>RetentionOffersAccepted</th>\n",
       "      <th>ReferralsMadeBySubscriber</th>\n",
       "      <th>IncomeGroup</th>\n",
       "      <th>AdjustmentsToCreditRating</th>\n",
       "      <th>HandsetPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.782676</td>\n",
       "      <td>-0.578738</td>\n",
       "      <td>-1.041153</td>\n",
       "      <td>-0.289532</td>\n",
       "      <td>-0.414422</td>\n",
       "      <td>-0.125914</td>\n",
       "      <td>-0.564836</td>\n",
       "      <td>-0.449987</td>\n",
       "      <td>-0.587303</td>\n",
       "      <td>-0.309284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.487071</td>\n",
       "      <td>-0.077013</td>\n",
       "      <td>1.387766</td>\n",
       "      <td>-0.883541</td>\n",
       "      <td>4.662897</td>\n",
       "      <td>-0.128300</td>\n",
       "      <td>-0.169283</td>\n",
       "      <td>-0.103411</td>\n",
       "      <td>-0.140707</td>\n",
       "      <td>-0.864858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.940180</td>\n",
       "      <td>-0.973177</td>\n",
       "      <td>-1.250809</td>\n",
       "      <td>-0.401714</td>\n",
       "      <td>-0.414422</td>\n",
       "      <td>-0.125914</td>\n",
       "      <td>0.029311</td>\n",
       "      <td>0.030120</td>\n",
       "      <td>-0.631532</td>\n",
       "      <td>-0.373230</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.616775</td>\n",
       "      <td>3.019920</td>\n",
       "      <td>0.392039</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>-0.180167</td>\n",
       "      <td>-0.128300</td>\n",
       "      <td>-0.169283</td>\n",
       "      <td>0.215243</td>\n",
       "      <td>-0.140707</td>\n",
       "      <td>-0.864858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.468118</td>\n",
       "      <td>-0.976952</td>\n",
       "      <td>-0.370255</td>\n",
       "      <td>-0.401714</td>\n",
       "      <td>-0.414422</td>\n",
       "      <td>-0.125914</td>\n",
       "      <td>0.037077</td>\n",
       "      <td>0.030120</td>\n",
       "      <td>-0.664703</td>\n",
       "      <td>-0.373230</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.616775</td>\n",
       "      <td>3.019920</td>\n",
       "      <td>-0.241605</td>\n",
       "      <td>0.202910</td>\n",
       "      <td>-0.180167</td>\n",
       "      <td>-0.128300</td>\n",
       "      <td>-0.169283</td>\n",
       "      <td>0.533896</td>\n",
       "      <td>-0.140707</td>\n",
       "      <td>-0.368174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.526784</td>\n",
       "      <td>1.484048</td>\n",
       "      <td>1.181196</td>\n",
       "      <td>0.154708</td>\n",
       "      <td>-0.414422</td>\n",
       "      <td>-0.125914</td>\n",
       "      <td>0.654524</td>\n",
       "      <td>0.234797</td>\n",
       "      <td>4.012499</td>\n",
       "      <td>0.330172</td>\n",
       "      <td>...</td>\n",
       "      <td>2.694763</td>\n",
       "      <td>0.305179</td>\n",
       "      <td>-0.060564</td>\n",
       "      <td>-0.883541</td>\n",
       "      <td>-0.180167</td>\n",
       "      <td>-0.128300</td>\n",
       "      <td>-0.169283</td>\n",
       "      <td>0.533896</td>\n",
       "      <td>-0.140707</td>\n",
       "      <td>-1.195980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.936810</td>\n",
       "      <td>-0.992050</td>\n",
       "      <td>-1.250809</td>\n",
       "      <td>-0.401714</td>\n",
       "      <td>-0.414422</td>\n",
       "      <td>-0.125914</td>\n",
       "      <td>0.044844</td>\n",
       "      <td>0.025066</td>\n",
       "      <td>-0.664703</td>\n",
       "      <td>-0.373230</td>\n",
       "      <td>...</td>\n",
       "      <td>1.590917</td>\n",
       "      <td>1.857585</td>\n",
       "      <td>0.663601</td>\n",
       "      <td>1.372934</td>\n",
       "      <td>-0.180167</td>\n",
       "      <td>-0.128300</td>\n",
       "      <td>-0.169283</td>\n",
       "      <td>1.489856</td>\n",
       "      <td>2.469282</td>\n",
       "      <td>-1.195980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51042</th>\n",
       "      <td>-0.233099</td>\n",
       "      <td>-0.301309</td>\n",
       "      <td>-0.076738</td>\n",
       "      <td>-0.289532</td>\n",
       "      <td>-0.383361</td>\n",
       "      <td>-0.125914</td>\n",
       "      <td>0.025428</td>\n",
       "      <td>0.022539</td>\n",
       "      <td>0.363618</td>\n",
       "      <td>-0.126582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.487071</td>\n",
       "      <td>0.573107</td>\n",
       "      <td>1.659328</td>\n",
       "      <td>1.790800</td>\n",
       "      <td>-0.180167</td>\n",
       "      <td>-0.128300</td>\n",
       "      <td>-0.169283</td>\n",
       "      <td>0.533896</td>\n",
       "      <td>-0.140707</td>\n",
       "      <td>-0.368174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51043</th>\n",
       "      <td>0.816402</td>\n",
       "      <td>2.301236</td>\n",
       "      <td>1.600507</td>\n",
       "      <td>0.042526</td>\n",
       "      <td>0.051479</td>\n",
       "      <td>0.352789</td>\n",
       "      <td>0.518608</td>\n",
       "      <td>0.431894</td>\n",
       "      <td>1.181852</td>\n",
       "      <td>-0.309284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.487071</td>\n",
       "      <td>0.328819</td>\n",
       "      <td>0.754122</td>\n",
       "      <td>1.122214</td>\n",
       "      <td>-0.180167</td>\n",
       "      <td>-0.128300</td>\n",
       "      <td>-0.169283</td>\n",
       "      <td>1.489856</td>\n",
       "      <td>2.469282</td>\n",
       "      <td>-0.368174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51044</th>\n",
       "      <td>-0.233099</td>\n",
       "      <td>-0.301309</td>\n",
       "      <td>-0.076738</td>\n",
       "      <td>-0.289532</td>\n",
       "      <td>-0.383361</td>\n",
       "      <td>-0.125914</td>\n",
       "      <td>0.025428</td>\n",
       "      <td>0.022539</td>\n",
       "      <td>4.012499</td>\n",
       "      <td>0.019579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.487071</td>\n",
       "      <td>-0.010031</td>\n",
       "      <td>0.210998</td>\n",
       "      <td>-0.883541</td>\n",
       "      <td>-0.180167</td>\n",
       "      <td>-0.128300</td>\n",
       "      <td>-0.169283</td>\n",
       "      <td>0.852549</td>\n",
       "      <td>2.469282</td>\n",
       "      <td>-0.037051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51045</th>\n",
       "      <td>-0.233099</td>\n",
       "      <td>-0.301309</td>\n",
       "      <td>-0.076738</td>\n",
       "      <td>-0.289532</td>\n",
       "      <td>-0.383361</td>\n",
       "      <td>-0.125914</td>\n",
       "      <td>0.025428</td>\n",
       "      <td>0.022539</td>\n",
       "      <td>-0.664703</td>\n",
       "      <td>-0.373230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.487071</td>\n",
       "      <td>0.206676</td>\n",
       "      <td>0.029957</td>\n",
       "      <td>-0.883541</td>\n",
       "      <td>-0.180167</td>\n",
       "      <td>-0.128300</td>\n",
       "      <td>-0.169283</td>\n",
       "      <td>1.489856</td>\n",
       "      <td>-0.140707</td>\n",
       "      <td>-0.864858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51046</th>\n",
       "      <td>-0.233099</td>\n",
       "      <td>-0.301309</td>\n",
       "      <td>-0.076738</td>\n",
       "      <td>-0.289532</td>\n",
       "      <td>-0.383361</td>\n",
       "      <td>-0.125914</td>\n",
       "      <td>0.025428</td>\n",
       "      <td>0.022539</td>\n",
       "      <td>1.402996</td>\n",
       "      <td>-0.309284</td>\n",
       "      <td>...</td>\n",
       "      <td>3.798609</td>\n",
       "      <td>-1.203887</td>\n",
       "      <td>-1.418373</td>\n",
       "      <td>-0.883541</td>\n",
       "      <td>4.662897</td>\n",
       "      <td>6.891363</td>\n",
       "      <td>-0.169283</td>\n",
       "      <td>-1.378025</td>\n",
       "      <td>2.469282</td>\n",
       "      <td>-0.368174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51047 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MonthlyRevenue  MonthlyMinutes  TotalRecurringCharge  \\\n",
       "0           -0.782676       -0.578738             -1.041153   \n",
       "1           -0.940180       -0.973177             -1.250809   \n",
       "2           -0.468118       -0.976952             -0.370255   \n",
       "3            0.526784        1.484048              1.181196   \n",
       "4           -0.936810       -0.992050             -1.250809   \n",
       "...               ...             ...                   ...   \n",
       "51042       -0.233099       -0.301309             -0.076738   \n",
       "51043        0.816402        2.301236              1.600507   \n",
       "51044       -0.233099       -0.301309             -0.076738   \n",
       "51045       -0.233099       -0.301309             -0.076738   \n",
       "51046       -0.233099       -0.301309             -0.076738   \n",
       "\n",
       "       DirectorAssistedCalls  OverageMinutes  RoamingCalls  PercChangeMinutes  \\\n",
       "0                  -0.289532       -0.414422     -0.125914          -0.564836   \n",
       "1                  -0.401714       -0.414422     -0.125914           0.029311   \n",
       "2                  -0.401714       -0.414422     -0.125914           0.037077   \n",
       "3                   0.154708       -0.414422     -0.125914           0.654524   \n",
       "4                  -0.401714       -0.414422     -0.125914           0.044844   \n",
       "...                      ...             ...           ...                ...   \n",
       "51042              -0.289532       -0.383361     -0.125914           0.025428   \n",
       "51043               0.042526        0.051479      0.352789           0.518608   \n",
       "51044              -0.289532       -0.383361     -0.125914           0.025428   \n",
       "51045              -0.289532       -0.383361     -0.125914           0.025428   \n",
       "51046              -0.289532       -0.383361     -0.125914           0.025428   \n",
       "\n",
       "       PercChangeRevenues  DroppedCalls  BlockedCalls  ...  HandsetModels  \\\n",
       "0               -0.449987     -0.587303     -0.309284  ...       0.487071   \n",
       "1                0.030120     -0.631532     -0.373230  ...      -0.616775   \n",
       "2                0.030120     -0.664703     -0.373230  ...      -0.616775   \n",
       "3                0.234797      4.012499      0.330172  ...       2.694763   \n",
       "4                0.025066     -0.664703     -0.373230  ...       1.590917   \n",
       "...                   ...           ...           ...  ...            ...   \n",
       "51042            0.022539      0.363618     -0.126582  ...       0.487071   \n",
       "51043            0.431894      1.181852     -0.309284  ...       0.487071   \n",
       "51044            0.022539      4.012499      0.019579  ...       0.487071   \n",
       "51045            0.022539     -0.664703     -0.373230  ...       0.487071   \n",
       "51046            0.022539      1.402996     -0.309284  ...       3.798609   \n",
       "\n",
       "       CurrentEquipmentDays    AgeHH1    AgeHH2  RetentionCalls  \\\n",
       "0                 -0.077013  1.387766 -0.883541        4.662897   \n",
       "1                  3.019920  0.392039  0.871495       -0.180167   \n",
       "2                  3.019920 -0.241605  0.202910       -0.180167   \n",
       "3                  0.305179 -0.060564 -0.883541       -0.180167   \n",
       "4                  1.857585  0.663601  1.372934       -0.180167   \n",
       "...                     ...       ...       ...             ...   \n",
       "51042              0.573107  1.659328  1.790800       -0.180167   \n",
       "51043              0.328819  0.754122  1.122214       -0.180167   \n",
       "51044             -0.010031  0.210998 -0.883541       -0.180167   \n",
       "51045              0.206676  0.029957 -0.883541       -0.180167   \n",
       "51046             -1.203887 -1.418373 -0.883541        4.662897   \n",
       "\n",
       "       RetentionOffersAccepted  ReferralsMadeBySubscriber  IncomeGroup  \\\n",
       "0                    -0.128300                  -0.169283    -0.103411   \n",
       "1                    -0.128300                  -0.169283     0.215243   \n",
       "2                    -0.128300                  -0.169283     0.533896   \n",
       "3                    -0.128300                  -0.169283     0.533896   \n",
       "4                    -0.128300                  -0.169283     1.489856   \n",
       "...                        ...                        ...          ...   \n",
       "51042                -0.128300                  -0.169283     0.533896   \n",
       "51043                -0.128300                  -0.169283     1.489856   \n",
       "51044                -0.128300                  -0.169283     0.852549   \n",
       "51045                -0.128300                  -0.169283     1.489856   \n",
       "51046                 6.891363                  -0.169283    -1.378025   \n",
       "\n",
       "       AdjustmentsToCreditRating  HandsetPrice  \n",
       "0                      -0.140707     -0.864858  \n",
       "1                      -0.140707     -0.864858  \n",
       "2                      -0.140707     -0.368174  \n",
       "3                      -0.140707     -1.195980  \n",
       "4                       2.469282     -1.195980  \n",
       "...                          ...           ...  \n",
       "51042                  -0.140707     -0.368174  \n",
       "51043                   2.469282     -0.368174  \n",
       "51044                   2.469282     -0.037051  \n",
       "51045                  -0.140707     -0.864858  \n",
       "51046                   2.469282     -0.368174  \n",
       "\n",
       "[51047 rows x 35 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[feature_list]\n",
    "y = df['Churn']\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Create Training and Test Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task</b>: Create training and test data sets out of the labeled examples. Save the results to variables `X_train, X_test, y_train, y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task</b>: Check the dimensions of the training and test data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34201, 35) (16846, 35) (34201,) (16846,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. Train a Logistic Regression Classifier and Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code cell below contains a function definition `train_test_LR()`. \n",
    "\n",
    "Inspect the function definition `train_test_LR(X_train, X_test, y_train, y_test, c=1)`. The function expects the training and test data sets, as well as a value for hyperparameter $C$. Note that we supplied the value of 1 for $C$ by default.\n",
    "\n",
    "<b>Task:</b> Complete the function to make it work.\n",
    "\n",
    "This function should:\n",
    "1. train a Logistic Regression model on the training data\n",
    "2. test the resulting model on the test data\n",
    "3. compute and return two items:\n",
    "    * the log loss of the resulting probability predictions on the test data \n",
    "    * the accuracy score of the resulting predicted class labels on the test data\n",
    "\n",
    "\n",
    "You will use the scikit-learn [```LogisticRegression``` class](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) and will provide the arguments `C=c` when creating the model object.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_LR(X_train, y_train, X_test, y_test, c=1):\n",
    "    '''\n",
    "    Fit a Linear Regression classifier to the training data X_train, y_train.\n",
    "    Return the loss and accuracy of resulting predictions on the test set.\n",
    "    Parameters:\n",
    "        C = Factor that controls how much regularization is applied to the model.\n",
    "    '''\n",
    "    \n",
    "    model = LogisticRegression(C=c)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_prob = model.predict_proba(X_test)\n",
    "    log_loss_value = log_loss(y_test, y_prob)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc_score = accuracy_score(y_test, y_pred)\n",
    "    return log_loss_value, acc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Model and Analyze the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> Use your function `train_test_LR()` to train one Logistic Regression classifier with the default value of hyperparameter C (`c=1`). Print the resulting log loss and accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5878612157234173 0.7097827377418972\n"
     ]
    }
   ],
   "source": [
    "log_loss_value, acc_score = train_test_LR(X_train, y_train, X_test, y_test, c=1)\n",
    "print(log_loss_value, acc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5. Train on Different Hyperparameter Values and Analyze the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will adjust the $C$ regularization hyperparameter to check its impact on the model's log loss and accuracy. Hyperparameter `C` stands for the inverse of regularization strength. Smaller values specify stronger regularization and a simpler model. Larger values specify weaker regularization and a more complex model.<br>\n",
    "\n",
    "The code cell below creates a list `cs` of twenty values of $C$.  Every item in the list has a value $10^i$ for every integer $i$ in the output of `range(-10,10)`. Run the code cell below and inspect the different values of $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1e-10,\n",
       " 1e-09,\n",
       " 1e-08,\n",
       " 1e-07,\n",
       " 1e-06,\n",
       " 1e-05,\n",
       " 0.0001,\n",
       " 0.001,\n",
       " 0.01,\n",
       " 0.1,\n",
       " 1,\n",
       " 10,\n",
       " 100,\n",
       " 1000,\n",
       " 10000,\n",
       " 100000,\n",
       " 1000000,\n",
       " 10000000,\n",
       " 100000000,\n",
       " 1000000000]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs = [10**i for i in range(-10,10)]\n",
    "cs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task</b>: In the code cell below, loop over list `cs` and train and evaluate a different Logistic Regression model for every value of $C$. Use your function `train_test_LR()`. Print the resulting log loss and accuracy scores per model.\n",
    "\n",
    "We will want to create visualizations that plot the resulting log loss and accuracy score for every value of hyperparameter $C$. Considering this, save the resulting log loss values and accuracy scores that your function returns to two different lists. You will use these lists to create plots later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6019882218839937 0.710198266650837\n",
      "0.6019879879688643 0.710198266650837\n",
      "0.6019856457586286 0.710198266650837\n",
      "0.6019623116656803 0.710198266650837\n",
      "0.6017368944992653 0.710198266650837\n",
      "0.6000102566181061 0.710198266650837\n",
      "0.5939550491932645 0.710198266650837\n",
      "0.5882530046237049 0.7104950730143654\n",
      "0.5876588226394373 0.7099014602873086\n",
      "0.587835892808505 0.7099014602873086\n",
      "0.5878612157234173 0.7097827377418972\n",
      "0.5878648343540094 0.7098420990146028\n",
      "0.5878651012583729 0.7098420990146028\n",
      "0.5878651279496574 0.7098420990146028\n",
      "0.5878651306188116 0.7098420990146028\n",
      "0.587865130885716 0.7098420990146028\n",
      "0.5878651309124132 0.7098420990146028\n",
      "0.5878651309150807 0.7098420990146028\n",
      "0.587865130915354 0.7098420990146028\n",
      "0.5878651309153761 0.7098420990146028\n"
     ]
    }
   ],
   "source": [
    "log_loss_result = []\n",
    "acc_score_result = []\n",
    "for c in cs:\n",
    "    log_loss_value, acc_score = train_test_LR(X_train, y_train, X_test, y_test, c=c)\n",
    "    log_loss_result.append(log_loss_value)\n",
    "    acc_score_result.append(acc_score)\n",
    "    print(log_loss_value, acc_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize the results. \n",
    "\n",
    "Before we create plots, let's reformat the hyperparameter values in list `cs` so that they can be easily visualized in our plots. We will take the log 10 of the hyperparameter values and save it to a new list called `cs_log10`. Let's take a look at the original values and transformed values:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1e-10, 1e-09, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000, 1000000, 10000000, 100000000, 1000000000]\n",
      "[-10.  -9.  -8.  -7.  -6.  -5.  -4.  -3.  -2.  -1.   0.   1.   2.   3.\n",
      "   4.   5.   6.   7.   8.   9.]\n"
     ]
    }
   ],
   "source": [
    "cs_log10 = np.log10(cs)\n",
    "\n",
    "print(cs)\n",
    "print(cs_log10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Plot Log Loss\n",
    "\n",
    "<b>Task:</b> Create a `seaborn` lineplot to plot the resulting log loss for every value of hyperparameter $C$. The hyperparameter $C$ should be plotted on the x axis and the log loss should be plotted on the y axis. Label the x and y axes accordingly. Use the transformed values of hyperparameter $C$ contained in the list `cs_log10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(x=cs_log10, y=log_loss_result, marker='o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Analysis</b>: Which value of $C$ yields the best results, in terms of loss?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best transformed C value: -2.0\n",
    "C value = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Accuracy\n",
    "\n",
    "<b>Task:</b> Create a `seaborn` lineplot to plot the resulting accuracy score for every value of hyperparameter $C$. The hyperparameter $C$ should be plotted on the x axis and the accuracy score should be plotted on the y axis. Label the x and y axes accordingly. Use the transformed values of hyperparameter $C$ contained in the list `cs_log10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(x=cs_log10, y=acc_score_result, marker='o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Analysis</b>: Which value of $C$ yields the best results, in terms of accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best transformed C value: -3.0\n",
    "C value = 0.001"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
